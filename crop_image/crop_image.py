# Crop and resize the image for CNN
# @author: Hang Wu
# @feedback: h.wu@tum.de
# @date: 2018.12.05

# from lxml import etree
import lxml.etree as etree
import tensorflow as tf
import cv2


def recursive_parse_xml_to_dict(xml):
    """Recursively parses XML contents to python dict.

    We assume that `object` tags are the only ones that can appear
    multiple times at the same level of a tree.

    Args:
      xml: xml tree obtained by parsing XML file contents using lxml.etree

    Returns:
      Python dictionary holding XML contents.
    """
    # if not xml:

    if not len(xml):
        return {xml.tag: xml.text}
    result = {}
    for child in xml:
        child_result = recursive_parse_xml_to_dict(child)
        if child.tag != 'object':
            result[child.tag] = child_result[child.tag]
        else:
            if child.tag not in result:
                result[child.tag] = []
            result[child.tag].append(child_result[child.tag])
    return {xml.tag: result}


# def dict_to_tf_example(data,
#                        mask_path,
#                        label_map_dict,
#                        image_subdirectory,
#                        ignore_difficult_instances=False,
#                        faces_only=True,
#                        mask_type='png'):
#   """Convert XML derived dict to tf.Example proto.

#   Notice that this function normalizes the bounding box coordinates provided
#   by the raw data.

#   Args:
#     data: dict holding PASCAL XML fields for a single image (obtained by
#       running dataset_util.recursive_parse_xml_to_dict)
#     mask_path: String path to PNG encoded mask.
#     label_map_dict: A map from string label names to integers ids.
#     image_subdirectory: String specifying subdirectory within the
#       Pascal dataset directory holding the actual image data.
#     ignore_difficult_instances: Whether to skip difficult instances in the
#       dataset  (default: False).
#     faces_only: If True, generates bounding boxes for pet faces.  Otherwise
#       generates bounding boxes (as well as segmentations for full pet bodies).
#     mask_type: 'numerical' or 'png'. 'png' is recommended because it leads to
#       smaller file sizes.

#   Returns:
#     example: The converted tf.Example.

#   Raises:
#     ValueError: if the image pointed to by data['filename'] is not a valid JPEG
#   """
#   img_path = os.path.join(image_subdirectory, data['filename'])
#   with tf.gfile.GFile(img_path, 'rb') as fid:
#     encoded_jpg = fid.read()
#   encoded_jpg_io = io.BytesIO(encoded_jpg)
#   image = PIL.Image.open(encoded_jpg_io)
#   if image.format != 'JPEG':
#     raise ValueError('Image format not JPEG')
#   key = hashlib.sha256(encoded_jpg).hexdigest()

#   with tf.gfile.GFile(mask_path, 'rb') as fid:
#     encoded_mask_png = fid.read()
#   encoded_png_io = io.BytesIO(encoded_mask_png)
#   mask = PIL.Image.open(encoded_png_io)
#   if mask.format != 'PNG':
#     raise ValueError('Mask format not PNG')

#   mask_np = np.asarray(mask)
#   nonbackground_indices_x = np.any(mask_np != 2, axis=0)
#   nonbackground_indices_y = np.any(mask_np != 2, axis=1)
#   nonzero_x_indices = np.where(nonbackground_indices_x)
#   nonzero_y_indices = np.where(nonbackground_indices_y)

#   width = int(data['size']['width'])
#   height = int(data['size']['height'])

#   xmins = []
#   ymins = []
#   xmaxs = []
#   ymaxs = []
#   classes = []
#   classes_text = []
#   truncated = []
#   poses = []
#   difficult_obj = []
#   masks = []
#   if 'object' in data:
#     for obj in data['object']:
#       difficult = bool(int(obj['difficult']))
#       if ignore_difficult_instances and difficult:
#         continue
#       difficult_obj.append(int(difficult))

#       if faces_only:
#         xmin = float(obj['bndbox']['xmin'])
#         xmax = float(obj['bndbox']['xmax'])
#         ymin = float(obj['bndbox']['ymin'])
#         ymax = float(obj['bndbox']['ymax'])
#       else:
#         xmin = float(np.min(nonzero_x_indices))
#         xmax = float(np.max(nonzero_x_indices))
#         ymin = float(np.min(nonzero_y_indices))
#         ymax = float(np.max(nonzero_y_indices))

#       xmins.append(xmin / width)
#       ymins.append(ymin / height)
#       xmaxs.append(xmax / width)
#       ymaxs.append(ymax / height)
#       class_name = get_class_name_from_filename(data['filename'])
#       classes_text.append(class_name.encode('utf8'))
#       classes.append(label_map_dict[class_name])
#       truncated.append(int(obj['truncated']))
#       poses.append(obj['pose'].encode('utf8'))
#       if not faces_only:
#         mask_remapped = (mask_np != 2).astype(np.uint8)
#         masks.append(mask_remapped)

#   feature_dict = {
#       'image/height': dataset_util.int64_feature(height),
#       'image/width': dataset_util.int64_feature(width),
#       'image/filename': dataset_util.bytes_feature(
#           data['filename'].encode('utf8')),
#       'image/source_id': dataset_util.bytes_feature(
#           data['filename'].encode('utf8')),
#       'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),
#       'image/encoded': dataset_util.bytes_feature(encoded_jpg),
#       'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),
#       'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
#       'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
#       'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
#       'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
#       'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
#       'image/object/class/label': dataset_util.int64_list_feature(classes),
#       'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),
#       'image/object/truncated': dataset_util.int64_list_feature(truncated),
#       'image/object/view': dataset_util.bytes_list_feature(poses),
#   }
#   if not faces_only:
#     if mask_type == 'numerical':
#       mask_stack = np.stack(masks).astype(np.float32)
#       masks_flattened = np.reshape(mask_stack, [-1])
#       feature_dict['image/object/mask'] = (
#           dataset_util.float_list_feature(masks_flattened.tolist()))
#     elif mask_type == 'png':
#       encoded_mask_png_list = []
#       for mask in masks:
#         img = PIL.Image.fromarray(mask)
#         output = io.BytesIO()
#         img.save(output, format='PNG')
#         encoded_mask_png_list.append(output.getvalue())
#       feature_dict['image/object/mask'] = (
#           dataset_util.bytes_list_feature(encoded_mask_png_list))

#   example = tf.train.Example(features=tf.train.Features(feature=feature_dict))
#   return example


xml_path = "car_door_0_0.xml"

with tf.gfile.GFile(xml_path, 'r') as fid:
    xml_str = fid.read()

xml = etree.fromstring(xml_str)

xml_dict = recursive_parse_xml_to_dict(xml)


print(xml_dict)
